{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_teddynote.tools.tavily import TavilySearch\n",
    "\n",
    "from typing import Annotated, TypedDict\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_teddynote.evaluator import GroundednessChecker\n",
    "from langchain_teddynote.messages import messages_to_history\n",
    "\n",
    "from langgraph.graph import END, StateGraph\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "from langchain_teddynote.messages import stream_graph, random_uuid\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "\n",
    "# Replace this deprecated import\n",
    "# from langchain.chat_models import ChatOpenAI\n",
    "from langchain_community.chat_models import ChatOpenAI  # Updated import\n",
    "\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "from langchain_core.messages import BaseMessage\n",
    "import os\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_teddynote.evaluator import GroundednessChecker\n",
    "from langchain_teddynote.messages import messages_to_history\n",
    "from langchain_teddynote.tools.tavily import TavilySearch\n",
    "\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 그래프 상태\n",
    "class TechSummaryAgent(TypedDict):\n",
    "    question: Annotated[str, \"Question\"] # 질문\n",
    "    context: Annotated[str, \"Context\"]\n",
    "    messages: Annotated[list[BaseMessage], \"Messages\"] # 메시지(누적되는 list)\n",
    "    relevance: Annotated[str, \"Relevance\"]  # 관련성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm_answer(state: TechSummaryAgent) -> TechSummaryAgent:\n",
    "    latest_question = state[\"question\"]\n",
    "    context = state[\"context\"]  # 웹 검색 결과로 받은 경쟁사 분석 정보\n",
    "\n",
    "    # 경쟁사 분석 결과를 요약하고 핵심 인사이트를 추출하는 프롬프트\n",
    "    report_prompt = f\"\"\"\n",
    "    당신은 {latest_question}의 기술력을 분석하는 전문가입니다.\n",
    "    주어진 정보를 바탕으로 다음 구조로 요약해주세요:\n",
    "\n",
    "    1. 핵심 기술 개요: 기업의 주요 기술과 특징을 간략하게 요약\n",
    "    2. 기술적 장점: 경쟁사 대비 우수한 점\n",
    "    3. 기술적 단점 또는 과제: 개선이 필요한 부분\n",
    "    4. 기술 경쟁력 평가: 전반적인 기술 경쟁력에 대한 평가\n",
    "\n",
    "    객관적인 사실에 기반하여 작성하고, 정보가 부족한 부분은 '정보 없음'으로 표시하세요.\n",
    "    기술 분석 정보 : {context}\n",
    "    \"\"\"\n",
    "\n",
    "    response = llm.invoke(report_prompt)\n",
    "\n",
    "    # 생성된 답변과 (유저의 질문, 답변) 메시지를 상태에 저장\n",
    "    return TechSummaryAgent(\n",
    "        answer=response,\n",
    "        messages=[(\"user\", latest_question), (\"assistant\", response)]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 관련성 체크 노드\n",
    "def relevance_check(state: TechSummaryAgent) -> TechSummaryAgent:\n",
    "    # 관련성 평가기 생성\n",
    "    question_answer_relevant = GroundednessChecker(\n",
    "        llm=ChatOpenAI(model=\"gpt-4o-mini\", temperature=0), target=\"question-retrieval\"\n",
    "    ).create()\n",
    "\n",
    "    # 관련성 체크를 실행(\"yes\" or \"no\")\n",
    "    response = question_answer_relevant.invoke(\n",
    "        {\"question\": state[\"question\"], \"context\": state[\"context\"]}\n",
    "        # {\"question\": state[\"question\"][-1].content, \"context\": state[\"context\"]}\n",
    "    )\n",
    "    # print(\"==== [RELEVANCE CHECK] ====\")  \n",
    "    # print(response.score)  \n",
    "    return TechSummaryAgent(relevance=response.score)\n",
    "\n",
    "\n",
    "# 관련성 체크하는 함수(router)\n",
    "def is_relevant(state: TechSummaryAgent) -> TechSummaryAgent:\n",
    "    return state[\"relevance\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Web Search 노드\n",
    "def web_search(state: TechSummaryAgent) -> TechSummaryAgent:\n",
    "    tavily_tool = TavilySearch()\n",
    "\n",
    "    search_query = state[\"question\"]\n",
    "    # search_query = state[\"question\"][-1].content\n",
    "\n",
    "    search_result = tavily_tool.search(\n",
    "        query=search_query,  # 검색 쿼리\n",
    "        topic=\"general\",     # 일반 주제\n",
    "        max_results=3,       # 최대 검색 결과\n",
    "        format_output=True,  # 결과 포맷팅\n",
    "    )\n",
    "\n",
    "    return TechSummaryAgent(context=\"\\n\".join(search_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query Rewrite 노드\n",
    "def query_rewrite(state: TechSummaryAgent) -> TechSummaryAgent:\n",
    "    \"\"\"\n",
    "    Rewrites a question to make it more effective for retrieving information about \n",
    "    a startup's core technologies and their strengths and weaknesses.\n",
    "    \n",
    "    Args:\n",
    "        state: TechSummaryAgent containing the original question\n",
    "        \n",
    "    Returns:\n",
    "        TechSummaryAgent with the rewritten question\n",
    "    \"\"\"\n",
    "    # Query Rewrite 프롬프트 정의\n",
    "    re_write_prompt = PromptTemplate(\n",
    "        template=\"\"\"You are an expert in query optimization for startup technology evaluation. Reformulate the given question to make it more effective for retrieving information about a startup's core technologies and their strengths and weaknesses.\n",
    "\n",
    "        - Identify the startup name and focus the reformulated question on retrieving detailed technical information.\n",
    "        - Ensure the rewritten query enables searching through sources like company websites, technical blogs, academic papers, and product documentation.\n",
    "        - Emphasize keywords related to technology overview, technical strengths, weaknesses, differentiation, and practical use cases.\n",
    "\n",
    "        # Output Format\n",
    "\n",
    "        - Provide a single, rewritten question.\n",
    "        - Do not include any explanatory or introductory text—output only the question.\n",
    "\n",
    "        # Examples\n",
    "\n",
    "        **Input**:\n",
    "        \"What is the technology behind MayAI?\"\n",
    "\n",
    "        **Output**:\n",
    "        \"What are the core technologies developed by MayAI, and what are their key advantages and limitations?\"\n",
    "\n",
    "        **Input**:\n",
    "        \"How good is Upstage's tech?\"\n",
    "\n",
    "        **Output**:\n",
    "        \"What AI technologies has Upstage developed, and how do their strengths and limitations compare to competitors?\"\n",
    "\n",
    "        # Notes\n",
    "\n",
    "        - The rewritten question must retain the original intent (evaluating technical capabilities).\n",
    "        - Avoid generic or overly simplified phrasing.\n",
    "        - Ensure the reformulated question is concise, technically focused, and suitable for information retrieval tasks.\n",
    "\n",
    "        # Original Question:\n",
    "        {question}\n",
    "        \"\"\",\n",
    "        input_variables=[\"question\"],\n",
    "    )\n",
    "\n",
    "    question_rewriter = (\n",
    "        re_write_prompt | ChatOpenAI(model=\"gpt-4o-mini\", temperature=0) | StrOutputParser()\n",
    "    )\n",
    "\n",
    "    latest_question = state[\"question\"]\n",
    "    question_rewritten = question_rewriter.invoke({\"question\": latest_question})\n",
    "\n",
    "    return TechSummaryAgent(question=question_rewritten)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기술 요약 정리 그래프 생성\n",
    "def create_tech_summary_graph():\n",
    "    workflow = StateGraph(TechSummaryAgent)\n",
    "\n",
    "    workflow.add_node(\"relevance_check\", relevance_check)\n",
    "    workflow.add_node(\"llm_answer\", llm_answer)\n",
    "    workflow.add_node(\"web_search\", web_search)\n",
    "    workflow.add_node(\"query_rewrite\", query_rewrite)  # Query Rewrite 노드 추가\n",
    "\n",
    "    workflow.add_edge(\"query_rewrite\", \"web_search\")      # 쿼리 재작성 -> 검색\n",
    "    workflow.add_edge(\"web_search\", \"relevance_check\")    # 검색 -> 관련성 체크\n",
    "\n",
    "\n",
    "    workflow.add_conditional_edges(\n",
    "        \"relevance_check\",\n",
    "        is_relevant,\n",
    "        {\n",
    "            \"yes\": \"llm_answer\",\n",
    "            \"no\": \"query_rewrite\",\n",
    "        },\n",
    "    )\n",
    "\n",
    "    workflow.add_edge(\"llm_answer\", END)\n",
    "\n",
    "    workflow.set_entry_point(\"query_rewrite\")\n",
    "\n",
    "    memory = MemorySaver()\n",
    "    return workflow.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def tech_analysis(company: str):\n",
    "    app = create_tech_summary_graph()\n",
    "    config = RunnableConfig(recursion_limit=10, configurable={\"thread_id\": random_uuid()})\n",
    "    inputs = TechSummaryAgent(question=company)\n",
    "    \n",
    "    # 그래프 실행\n",
    "    result = await app.ainvoke(inputs, config)\n",
    "    \n",
    "    # 결과에서 messages 리스트 가져오기\n",
    "    messages = result.get(\"messages\", [])\n",
    "    \n",
    "    # messages가 비어있지 않다면 마지막 메시지의 AIMessage content 반환\n",
    "    if messages and messages[-1]:\n",
    "        last_message = messages[-1]\n",
    "        \n",
    "        # 튜플 형태이고 두 번째 요소가 AIMessage 객체인 경우\n",
    "        if isinstance(last_message, tuple) and len(last_message) > 1 and hasattr(last_message[1], 'content'):\n",
    "            return last_message[1].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### 1. 핵심 기술 개요\n",
      "메이아이(주)는 영상처리 인공지능 스타트업으로, 자사 솔루션인 '매쉬(mAsh)'를 통해 사람 재식별(AI Re-ID) 기술을 개발하고 있습니다. 이 기술은 CCTV 환경에 따른 편향을 줄여 다양한 조건에서도 일관된 정확도를 유지할 수 있도록 설계되어 있습니다. 최근 '사람 재식별 AI 모델의 카메라 편향에 대한 연구' 논문이 세계적인 AI 학술대회인 '표현학습국제학회(ICLR) 2025'에서 상위 5%에 선정되었습니다.\n",
      "\n",
      "### 2. 기술적 장점\n",
      "- **높은 정확도**: 메이아이의 Re-ID 기술은 내부 테스트에서 최신 학계 모델(ISR, 66%)을 뛰어넘는 92%의 정확도를 기록했습니다.\n",
      "- **효율성 극대화**: 적은 인력으로도 높은 정확도를 구현하여 다양한 매장에서 운영 효율성을 극대화할 수 있습니다.\n",
      "- **개인정보 보호**: 기술적으로 개인정보를 보호하면서도 정밀한 매장 방문객 데이터를 제공할 수 있습니다.\n",
      "  \n",
      "### 3. 기술적 단점 또는 과제\n",
      "- **환경적 편향 문제**: 기존 AI 모델들이 CCTV별 환경 차이로 인해 동일한 사람을 명확하게 판별하기 어려운 한계를 가지고 있으며, 이를 개선하기 위한 지속적인 연구와 개발이 필요합니다.\n",
      "- **정보 없음**: 특정한 기술적 단점 또는 과제에 대한 상세한 정보는 제공되지 않았습니다.\n",
      "\n",
      "### 4. 기술 경쟁력 평가\n",
      "메이아이는 최신 AI 기술을 바탕으로 높은 정확도와 효율성을 제공하며, 전 세계적으로 인정받는 연구 결과를 기반으로 기술 경쟁력이 강한 기업으로 평가됩니다. 그러나 CCTV 환경에 따른 편향 문제와 같은 도전 과제가 있으며, 이를 해결하기 위한 지속적인 노력이 요구됩니다. 전반적으로 메이아이의 기술은 시장에서 유의미한 경쟁력을 지니고 있습니다.\n"
     ]
    }
   ],
   "source": [
    "result = await tech_analysis(\"메이아이\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(app.get_graph().draw_ascii())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-kr-607HAWwd-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
